{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3年前就讀高雄應用大學二年級的陳顯佳\n",
      "為閃避跨越雙黃線來車\n",
      "撞上路邊\n",
      "摔斷頸椎\n",
      "頸部以下全癱\n",
      "嘴被插管\n",
      "父母每天去看他\n",
      "他都意識清醒\n",
      "眨眼流淚\n",
      "17天後他因頸椎受損抑制呼吸\n",
      "醫師用盡強力針與電擊都無效\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "delimiter = \"，|。|、|？\"  \n",
    "text = '3年前就讀高雄應用大學二年級的陳顯佳，為閃避跨越雙黃線來車，撞上路邊、摔斷頸椎，頸部以下全癱，嘴被插管，父母每天去看他，他都意識清醒、眨眼流淚，17天後他因頸椎受損抑制呼吸，醫師用盡強力針與電擊都無效，'\n",
    "for i in re.split(delimiter, text):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          周年慶    3歲         \n",
      "    大拍賣\n"
     ]
    }
   ],
   "source": [
    "w = '          周年慶    3歲         \\n    大拍賣'\n",
    "print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xe5\\x91\\xa8\\xe5\\xb9\\xb4\\xe6\\x85\\xb6', '3\\xe6\\xad\\xb2', '\\xe5\\xa4\\xa7\\xe6\\x8b\\x8d\\xe8\\xb3\\xa3']\n",
      "周年慶\n",
      "3歲\n",
      "大拍賣\n"
     ]
    }
   ],
   "source": [
    "print w.split()\n",
    "for i in w.split():\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "周年慶|3歲|大拍賣\n"
     ]
    }
   ],
   "source": [
    "print '|'.join(w.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xe6\\xb0\\x91\\xe9\\x80\\xb2\\xe9\\xbb\\xa8', '\\xe5\\xb0\\x87\\xe5\\x85\\xac\\xe5\\xb8\\x83']\n",
      "民進黨\n",
      "將公布\n"
     ]
    }
   ],
   "source": [
    "a = '民進黨後天將公布'\n",
    "print a.split('後天')\n",
    "for i in a.split('後天'):\n",
    "    print i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "民進黨將公布\n"
     ]
    }
   ],
   "source": [
    "print ''.join(a.split('後天'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeKey(text, keyword):\n",
    "    textAry= text\n",
    "    for key in keyword:\n",
    "        textAry = ''.join(textAry.split(key))\n",
    "    return textAry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "民進黨將公布\n",
      "將公布\n"
     ]
    }
   ],
   "source": [
    "a = '民進黨後天將公布'\n",
    "print removeKey(a, ['後天'])\n",
    "\n",
    "\n",
    "a = '民進黨後天將公布'\n",
    "print removeKey(a, ['民進黨', '後天'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitSentense(text, delimiter):\n",
    "    return re.split(delimiter, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delimiter = \"，|。|、|（|）|／|《|》|】|【|「|」|；|：|！\".decode('utf-8')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = sqlite3.connect('news2.sqlite') \n",
    "cur = db.cursor()\n",
    "cur.execute('select title, summary from news_entry limit 200')\n",
    "allNews = cur.fetchall()\n",
    "sentenceAry = []\n",
    "for rec in allNews:\n",
    "    text = rec[1]\n",
    "    sentenceAry += splitSentense(text,delimiter)\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9192\n"
     ]
    }
   ],
   "source": [
    "print len(sentenceAry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram(input_sentence, n = 2):\n",
    "    word_dic = {}\n",
    "    sentence  = input_sentence\n",
    "    for i in range(0, len(sentence) - n + 1):        \n",
    "        if sentence[i:i+n] not in word_dic:\n",
    "            word_dic[sentence[i:i+n]] = 1\n",
    "        else:\n",
    "            word_dic[sentence[i:i+n]] = word_dic[sentence[i:i+n]] + 1\n",
    "    return word_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords=[]        \n",
    "ret_terms={}\n",
    "words_freq    = []\n",
    "for term_length in range(4,1,-1):\n",
    "    word_dic = {}\n",
    "    for sentence in sentenceAry:\n",
    "        text_list = removeKey(sentence,keywords)        \n",
    "        ngram_words = ngram(text_list,term_length) \n",
    "        for word in ngram_words:\n",
    "            if word not in word_dic:\n",
    "                word_dic[word] = 1\n",
    "            else:\n",
    "                word_dic[word] += ngram_words[word]   \n",
    "    for word in word_dic:\n",
    "        if word_dic[word] >= 5:\n",
    "            keywords.append(word)            \n",
    "            ret_terms.update({word:word_dic[word]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_terms = sorted(ret_terms.iteritems(),key=operator.itemgetter(1),reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "表示 96\n",
      "台北報導 62\n",
      "台灣 58\n",
      "自己 56\n",
      "沒有 55\n",
      "提供 53\n",
      "10 51\n",
      "中國 50\n",
      "報導 50\n",
      "美國 48\n",
      "目前 48\n",
      "11 48\n",
      "問題 47\n",
      "朱立倫 47\n",
      "可以 45\n",
      "認為 44\n",
      "英國 44\n",
      "更新 44\n",
      "蘋果 44\n",
      "對於 44\n",
      "發現 44\n",
      "希望 43\n",
      "今天 43\n",
      "網友 43\n",
      "指出 43\n",
      "中心 42\n",
      "可能 42\n",
      "就是 41\n",
      "民眾 40\n",
      "不過 40\n"
     ]
    }
   ],
   "source": [
    "for term in sorted_terms[0:30]:\n",
    "    print term[0], term[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Python27\\lib\\site-packages\\jieba\\dict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from C:\\Python27\\lib\\site-packages\\jieba\\dict.txt ...\n",
      "Loading model from cache c:\\users\\user\\appdata\\local\\temp\\jieba.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\user\\appdata\\local\\temp\\jieba.cache\n",
      "Loading model cost 0.578 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.578 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 大/ 巨蛋/ 案/ 對/ 市府/ 同仁/ 下/ 封口/ 封口令/ 口令/ / / / 柯/ P/ 否/ 認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=True)\n",
    "print \"Full Mode:\", \"/ \".join(seg_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 大/ 巨蛋/ 案/ 對/ 市府/ 同仁/ 下/ 封口/ 封口令/ 口令/ / / / 柯/ P/ 否/ 認\n",
      "Default Mode: 大/ 巨蛋/ 案對/ 市府/ 同仁/ 下/ 封口令/ ？/ 　/ 柯/ P/ 否認\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=True)\n",
    "print \"Full Mode:\", \"/ \".join(seg_list) \n",
    "\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=False)\n",
    "print \"Default Mode:\", \"/ \".join(seg_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大 a\n",
      "巨蛋 n\n",
      "案 ng\n",
      "對 p\n",
      "市府 n\n",
      "同仁 nr\n",
      "下 f\n",
      "封口令 n\n",
      "？ x\n",
      "　x\n",
      "柯 nr\n",
      "P eng\n",
      "否認 v\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "for w in words:\n",
    "    print w.word, w.flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大/ 巨蛋/ 案對/ 市府/ 同仁/ 下/ 封口令/ ？/ 　/ 柯/ P/ 否認\n"
     ]
    }
   ],
   "source": [
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "words = jieba.cut(sentence, cut_all=False)\n",
    "print \"/ \".join(words) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jieba.add_word('柯P',100, 'nr')\n",
    "jieba.add_word('大巨蛋',100, 'ns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋/ 案對/ 市府/ 同仁/ 下/ 封口令/ ？/ 　/ 柯P/ 否認\n"
     ]
    }
   ],
   "source": [
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "words = jieba.cut(sentence, cut_all=False)\n",
    "print \"/ \".join(words) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋 0 3\n",
      "案對 3 5\n",
      "市府 5 7\n",
      "同仁 7 9\n",
      "下 9 10\n",
      "封口令 10 13\n",
      "？ 13 14\n",
      "　14 15\n",
      "柯P 15 17\n",
      "否認 17 19\n"
     ]
    }
   ],
   "source": [
    "words = jieba.tokenize(unicode(sentence, 'utf-8'))\n",
    "\n",
    "for tw in words:\n",
    "    print tw[0], tw[1], tw[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "封口令\n",
      "柯P\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags(sentence, 1)\n",
    "print \",\".join(tags)\n",
    "tags = jieba.analyse.extract_tags(sentence, 1, allowPOS = ['nr'])\n",
    "print \",\".join(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
